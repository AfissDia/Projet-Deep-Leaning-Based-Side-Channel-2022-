{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750a5e3f",
   "metadata": {},
   "source": [
    "# <center><span style='color:Blue'>Projet Deep Leaning Based Side Channel</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338c48b",
   "metadata": {},
   "source": [
    "## <center><span style='color:red'>Master MS2E</span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e8c9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, AveragePooling1D, BatchNormalization, Activation, Add, add\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af7d28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(file_path):\n",
    "    file_path = os.path.normpath(file_path)\n",
    "    if os.path.exists(file_path) == False:\n",
    "        print(\"Error: provided file path '%s' does not exist!\" % file_path)\n",
    "        sys.exit(-1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1153e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MLP Best model (6 layers of 200 units)\n",
    "# def mlp_best(node=200,layer_nb=6,input_dim=1400):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(node, input_dim=input_dim, activation='relu'))\n",
    "#     for i in range(layer_nb-2):\n",
    "#         model.add(Dense(node, activation='relu'))\n",
    "#     model.add(Dense(256, activation='softmax'))\n",
    "#     optimizer = RMSprop(lr=0.00001)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e8ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mlp(input_dim=1000):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,  input_dim=input_dim, name='dia'))\n",
    "    model.add(Activation('softmax'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.5)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194a364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "101f5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resnet layer sub-function of ResNetSCA\n",
    "def resnet_layer(inputs, num_filters=16, kernel_size=11, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
    "\tconv = Conv1D(num_filters,\n",
    "\t\t\t\t  kernel_size=kernel_size,\n",
    "\t\t\t\t  strides=strides,\n",
    "\t\t\t\t  padding='same',\n",
    "\t\t\t\t  kernel_initializer='he_normal')\n",
    "\n",
    "\tx = inputs\n",
    "\tif conv_first:\n",
    "\t\tx = conv(x)\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\telse:\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\t\tx = conv(x)\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "767225a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branch of ResNetSCA that predict the multiplicative mask alpha\n",
    "def alpha_branch(x):\n",
    "\tx = Dense(1024, activation='relu', name='fc1_alpha')(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(256, activation=\"softmax\", name='alpha_output')(x)\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df36a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branch of ResNetSCA that predict the additive mask beta\n",
    "def beta_branch(x):\n",
    "\tx = Dense(1024, activation='relu', name='fc1_beta')(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(256, activation=\"softmax\", name='beta_output')(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ee6662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branch of ResNetSCA that predict the masked sbox output\n",
    "def sbox_branch(x,i):\n",
    "\tx = Dense(1024, activation='relu', name='fc1_sbox_'+str(i))(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(256, activation=\"softmax\", name='sbox_'+str(i)+'_output')(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77044199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Branch of ResNetSCA that predict the pemutation indices\n",
    "def permind_branch(x,i):\n",
    "\tx = Dense(1024, activation='relu', name='fc1_pemind_'+str(i))(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(16, activation=\"softmax\", name='permind_'+str(i)+'_output')(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e8d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generic function that produce the ResNetSCA architecture.\n",
    "### If without_permind option is set to 1, the ResNetSCA model is built without permindices branch\n",
    "def resnet_v1(input_shape, depth, num_classes=256, without_permind=0):\n",
    "\tif (depth - 1) % 18 != 0:\n",
    "\t\traise ValueError('depth should be 18n+1 (eg 19, 37, 55 ...)')\n",
    "\t# Start model definition.\n",
    "\tnum_filters = 16\n",
    "\tnum_res_blocks = int((depth - 1) / 18)\n",
    "\tinputs = Input(shape=input_shape)\n",
    "\tx = resnet_layer(inputs=inputs)\n",
    "\t# Instantiate the stack of residual units\n",
    "\tfor stack in range(9):\n",
    "\t\tfor res_block in range(num_res_blocks):\n",
    "\t\t\tstrides = 1\n",
    "\t\t\tif stack > 0 and res_block == 0:\n",
    "\t\t\t\tstrides = 2\n",
    "\t\t\ty = resnet_layer(inputs=x,\n",
    "\t\t\t\t\t\t\t num_filters=num_filters,\n",
    "\t\t\t\t\t\t\t strides=strides)\n",
    "\t\t\ty = resnet_layer(inputs=y,\n",
    "\t\t\t\t\t\t\t num_filters=num_filters,\n",
    "\t\t\t\t\t\t\t activation=None)\n",
    "\t\t\tif stack > 0 and res_block == 0:\n",
    "\t\t\t\tx = resnet_layer(inputs=x,\n",
    "\t\t\t\t\t\t\t\t num_filters=num_filters,\n",
    "\t\t\t\t\t\t\t\t kernel_size=1,\n",
    "\t\t\t\t\t\t\t\t strides=strides,\n",
    "\t\t\t\t\t\t\t\t activation=None,\n",
    "\t\t\t\t\t\t\t\t batch_normalization=False)\n",
    "\t\t\tx = add([x, y])\n",
    "\t\t\tx = Activation('relu')(x)\n",
    "\t\tif (num_filters<256):\n",
    "\t\t\tnum_filters *= 2\n",
    "\tx = AveragePooling1D(pool_size=4)(x)\n",
    "\tx = Flatten()(x)\n",
    "\tx_alpha = alpha_branch(x)\n",
    "\tx_beta = beta_branch(x)\n",
    "\tx_sbox_l = []\n",
    "\tx_permind_l = []\n",
    "\tfor i in range(16):\n",
    "\t\tx_sbox_l.append(sbox_branch(x,i))\n",
    "\t\tx_permind_l.append(permind_branch(x,i))\n",
    "\tif without_permind!=1:\n",
    "\t  model = Model(inputs, [x_alpha, x_beta] + x_sbox_l + x_permind_l, name='extract_resnet')\n",
    "\telse:\n",
    "\t  model = Model(inputs, [x_alpha, x_beta] + x_sbox_l, name='extract_resnet_without_permind')\n",
    "\toptimizer = Adam()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5dda6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c8fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN multilabel test function. This model is only used for debugging.\n",
    "def multi_test(input_dim=500):\n",
    "\tinput_shape = (input_dim,1)\n",
    "\tinputs = Input(shape=input_shape)\n",
    "\t# Block 1\n",
    "\tx = Conv1D(3, 11, strides=100, activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "\tx = Flatten()(x)\n",
    "\tx_alpha = alpha_branch(x)\n",
    "\tx_beta = beta_branch(x)\n",
    "\tx_sbox_l = []\n",
    "\tx_permind_l = []\n",
    "\tfor i in range(16):\n",
    "\t\tx_sbox_l.append(sbox_branch(x,i))\n",
    "\t\tx_permind_l.append(permind_branch(x,i))\n",
    "\tmodel = Model(inputs, [x_alpha, x_beta] + x_sbox_l + x_permind_l, name='test_multi')\n",
    "\toptimizer = Adam()\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c1073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sca_model(model_file):\n",
    "\tcheck_file_exists(model_file)\n",
    "\ttry:\n",
    "\t\t\tmodel = load_model(model_file)\n",
    "\texcept:\n",
    "\t\tprint(\"Error: can't load Keras model file '%s'\" % model_file)\n",
    "\t\tsys.exit(-1)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ASCAD helper to load profiling and attack data (traces and labels)\n",
    "# Loads the profiling and attack datasets from the ASCAD\n",
    "# database\n",
    "def load_ascad(ascad_database_file, load_metadata=False):\n",
    "\tcheck_file_exists(ascad_database_file)\n",
    "\t# Open the ASCAD database HDF5 for reading\n",
    "\ttry:\n",
    "\t\tin_file\t = h5py.File(ascad_database_file, \"r\")\n",
    "\texcept:\n",
    "\t\tprint(\"Error: can't open HDF5 file '%s' for reading (it might be malformed) ...\" % ascad_database_file)\n",
    "\t\tsys.exit(-1)\n",
    "\t# Load profiling traces\n",
    "\tX_profiling = np.array(in_file['Profiling_traces/traces'], dtype=np.int8)\n",
    "\t# Load profiling labels\n",
    "\tY_profiling = np.array(in_file['Profiling_traces/labels'])\n",
    "\t# Load attacking traces\n",
    "\tX_attack = np.array(in_file['Attack_traces/traces'], dtype=np.int8)\n",
    "\t# Load attacking labels\n",
    "\tY_attack = np.array(in_file['Attack_traces/labels'])\n",
    "\tif load_metadata == False:\n",
    "\t\treturn (X_profiling, Y_profiling), (X_attack, Y_attack)\n",
    "\telse:\n",
    "\t\treturn (X_profiling, Y_profiling), (X_attack, Y_attack), (in_file['Profiling_traces/metadata'], in_file['Attack_traces/metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f863c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b7df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_to_categorical(Y):\n",
    "\ty = {}\n",
    "\ty['alpha_output'] = to_categorical(Y['alpha_mask'], num_classes=256)\n",
    "\ty['beta_output'] = to_categorical(Y['beta_mask'], num_classes=256)\n",
    "\tfor i in range(16):\n",
    "\t\ty['sbox_'+str(i)+'_output'] = to_categorical(Y['sbox_masked'][:,i], num_classes=256)\n",
    "\tfor i in range(16):\n",
    "\t\ty['permind_'+str(i)+'_output'] = to_categorical(Y['perm_index'][:,i], num_classes=16)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f4610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_without_permind_to_categorical(Y):\n",
    "\ty = {}\n",
    "\ty['alpha_output'] = to_categorical(Y['alpha_mask'], num_classes=256)\n",
    "\ty['beta_output'] = to_categorical(Y['beta_mask'], num_classes=256)\n",
    "\tfor i in range(16):\n",
    "\t\ty['sbox_'+str(i)+'_output'] = to_categorical(Y['sbox_masked_with_perm'][:,i], num_classes=256)\n",
    "\treturn y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765ad268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training high level function\n",
    "def train_model(X_profiling, Y_profiling, model, save_file_name, epochs=150, batch_size=100, multilabel=0, validation_split=0, early_stopping=0):\n",
    "\tcheck_file_exists(os.path.dirname(save_file_name))\n",
    "\t# Save model calllback\n",
    "\tsave_model = ModelCheckpoint(save_file_name)\n",
    "\tcallbacks=[save_model]\n",
    "\t# Early stopping callback\n",
    "\tif (early_stopping != 0):\n",
    "\t\tif validation_split == 0:\n",
    "\t\t\tvalidation_split=0.1\n",
    "\t\tcallbacks.append(EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True))\n",
    "\t# Get the input layer shape\n",
    "\tif isinstance(model.get_layer(index=0).input_shape, list):\n",
    "\t\tinput_layer_shape = model.get_layer(index=0).input_shape[0]\n",
    "\telse:\n",
    "\t\tinput_layer_shape = model.get_layer(index=0).input_shape\n",
    "\t# Sanity check\n",
    "\tif input_layer_shape[1] != len(X_profiling[0]):\n",
    "\t\tprint(\"Error: model input shape %d instead of %d is not expected ...\" % (input_layer_shape[1], len(X_profiling[0])))\n",
    "\t\tsys.exit(-1)\n",
    "\t# Adapt the data shape according our model input\n",
    "\tif len(input_layer_shape) == 2:\n",
    "\t\t# This is a MLP\n",
    "\t\tReshaped_X_profiling = X_profiling\n",
    "\telif len(input_layer_shape) == 3:\n",
    "\t\t# This is a CNN: expand the dimensions\n",
    "\t\tReshaped_X_profiling = X_profiling.reshape((X_profiling.shape[0], X_profiling.shape[1], 1))\n",
    "\telse:\n",
    "\t\tprint(\"Error: model input shape length %d is not expected ...\" % len(input_layer_shape))\n",
    "\t\tsys.exit(-1)\n",
    "\tif (multilabel==1):\n",
    "\t\ty=multilabel_to_categorical(Y_profiling)\n",
    "\telif (multilabel==2):\n",
    "\t\ty=multilabel_without_permind_to_categorical(Y_profiling)\n",
    "\telse:\n",
    "\t\ty=to_categorical(Y_profiling, num_classes=256)\n",
    "\thistory = model.fit(x=Reshaped_X_profiling, y=y, batch_size=batch_size, verbose = 1, validation_split=validation_split, epochs=epochs, callbacks=callbacks)\n",
    "\treturn history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3e8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2d5107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameters_from_file(param_filename):\n",
    "\t#read parameters for the train_model and load_ascad functions\n",
    "\t#TODO: sanity checks on parameters\n",
    "\tparam_file = open(param_filename,\"r\")\n",
    "\n",
    "\t#TODO: replace eval() by ast.linear_eval()\n",
    "\tmy_parameters= eval(param_file.read())\n",
    "\n",
    "\tascad_database = my_parameters[\"ascad_database\"]\n",
    "\ttraining_model = my_parameters[\"training_model\"]\n",
    "\tnetwork_type = my_parameters[\"network_type\"]\n",
    "\tepochs = my_parameters[\"epochs\"]\n",
    "\tbatch_size = my_parameters[\"batch_size\"]\n",
    "\ttrain_len = 0\n",
    "\tif (\"train_len\" in my_parameters):\n",
    "\t\ttrain_len = my_parameters[\"train_len\"]\n",
    "\tvalidation_split = 0\n",
    "\tif (\"validation_split\" in my_parameters):\n",
    "\t\tvalidation_split = my_parameters[\"validation_split\"]\n",
    "\tmultilabel = 0\n",
    "\tif (\"multilabel\" in my_parameters):\n",
    "\t\tmultilabel = my_parameters[\"multilabel\"]\n",
    "\tearly_stopping = 0\n",
    "\tif (\"early_stopping\" in my_parameters):\n",
    "\t\tearly_stopping = my_parameters[\"early_stopping\"]\n",
    "\treturn ascad_database, training_model, network_type, epochs, batch_size, train_len, validation_split, multilabel, early_stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f538d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "463bf55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dia (Dense)                 (None, 256)               179456    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,456\n",
      "Trainable params: 179,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 114492.3672 - accuracy: 0.0040 - val_loss: 139627.2031 - val_accuracy: 0.0046\n",
      "Epoch 2/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 124401.6953 - accuracy: 0.0034 - val_loss: 118278.7188 - val_accuracy: 0.0036\n",
      "Epoch 3/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 123262.8750 - accuracy: 0.0037 - val_loss: 117832.8828 - val_accuracy: 0.0036\n",
      "Epoch 4/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 124712.0703 - accuracy: 0.0042 - val_loss: 121493.3750 - val_accuracy: 0.0050\n",
      "Epoch 5/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 121697.1094 - accuracy: 0.0042 - val_loss: 123058.9922 - val_accuracy: 0.0050\n",
      "Epoch 6/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 122906.1250 - accuracy: 0.0040 - val_loss: 114109.1328 - val_accuracy: 0.0048\n",
      "Epoch 7/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 123968.7500 - accuracy: 0.0040 - val_loss: 123798.9219 - val_accuracy: 0.0048\n",
      "Epoch 8/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 123032.1172 - accuracy: 0.0037 - val_loss: 129379.1719 - val_accuracy: 0.0042\n",
      "Epoch 9/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 120815.5234 - accuracy: 0.0039 - val_loss: 116277.1172 - val_accuracy: 0.0054\n",
      "Epoch 10/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 120177.1406 - accuracy: 0.0043 - val_loss: 125148.1719 - val_accuracy: 0.0026\n",
      "Epoch 11/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 119354.1094 - accuracy: 0.0040 - val_loss: 125049.0625 - val_accuracy: 0.0036\n",
      "Epoch 12/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 118888.7969 - accuracy: 0.0038 - val_loss: 124456.3828 - val_accuracy: 0.0050\n",
      "Epoch 13/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 119239.4766 - accuracy: 0.0040 - val_loss: 126800.4453 - val_accuracy: 0.0038\n",
      "Epoch 14/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 120475.8047 - accuracy: 0.0036 - val_loss: 114035.9531 - val_accuracy: 0.0042\n",
      "Epoch 15/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 118661.5547 - accuracy: 0.0044 - val_loss: 131024.1797 - val_accuracy: 0.0056\n",
      "Epoch 16/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 120473.2812 - accuracy: 0.0035 - val_loss: 117745.5391 - val_accuracy: 0.0024\n",
      "Epoch 17/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 120675.2969 - accuracy: 0.0042 - val_loss: 113316.3047 - val_accuracy: 0.0032\n",
      "Epoch 18/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 118323.0547 - accuracy: 0.0040 - val_loss: 120183.5547 - val_accuracy: 0.0028\n",
      "Epoch 19/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 117747.5078 - accuracy: 0.0045 - val_loss: 115453.9609 - val_accuracy: 0.0052\n",
      "Epoch 20/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 118118.9375 - accuracy: 0.0048 - val_loss: 108340.7266 - val_accuracy: 0.0022\n",
      "Epoch 21/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 117820.0156 - accuracy: 0.0045 - val_loss: 109538.7422 - val_accuracy: 0.0046\n",
      "Epoch 22/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 117001.8672 - accuracy: 0.0043 - val_loss: 112340.7578 - val_accuracy: 0.0042\n",
      "Epoch 23/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 114703.4531 - accuracy: 0.0040 - val_loss: 122497.0781 - val_accuracy: 0.0048\n",
      "Epoch 24/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 115691.6875 - accuracy: 0.0043 - val_loss: 121291.0703 - val_accuracy: 0.0040\n",
      "Epoch 25/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 118996.8125 - accuracy: 0.0040 - val_loss: 121738.8125 - val_accuracy: 0.0038\n",
      "Epoch 26/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 117700.7578 - accuracy: 0.0042 - val_loss: 116930.0469 - val_accuracy: 0.0058\n",
      "Epoch 27/75\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 117496.7656 - accuracy: 0.0043 - val_loss: 125269.9375 - val_accuracy: 0.0038\n",
      "Epoch 28/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 115778.8906 - accuracy: 0.0040 - val_loss: 110441.0859 - val_accuracy: 0.0048\n",
      "Epoch 29/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 117103.3281 - accuracy: 0.0044 - val_loss: 120094.4141 - val_accuracy: 0.0040\n",
      "Epoch 30/75\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 115820.6094 - accuracy: 0.0043 - val_loss: 118349.6328 - val_accuracy: 0.0046\n"
     ]
    }
   ],
   "source": [
    "early_stopping = 0.1\n",
    "if __name__ == \"__main__\":\n",
    "\tif len(sys.argv)!=2:\n",
    "\t\t#default parameters values\n",
    "\t\tascad_database = \"../ATMEGA_AES_v1/ATM_AES_v1_fixed_key/ASCAD_data/ASCAD_databases/ASCAD.h5\"\n",
    "\t\t#MLP training\n",
    "\t\tnetwork_type = \"mlp\"\n",
    "\t\ttraining_model = \"../ATMEGA_AES_v1/ATM_AES_v1_fixed_key/ASCAD_data/ASCAD_trained_models/my_mlp_best_desync0_epochs75_batchsize200.h5\"\n",
    "\n",
    "\t\t#CNN training\n",
    "\t\t#network_type = \"cnn\"\n",
    "\t\t#training_model = \"ATMEGA_AES_v1/ATM_AES_v1_fixed_key/ASCAD_data/ASCAD_trained_models/my_cnn_best_desync0_epochs75_batchsize200.h5\"\n",
    "\n",
    "\t\t#CNN training\n",
    "\t\t#network_type = \"cnn2\"\n",
    "\t\t#training_model = \"ATMEGA_AES_v1/ATM_AES_v1_fixed_key/ASCAD_data/ASCAD_trained_models/my_cnn_best_desync0_epochs75_batchsize200.h5\"\n",
    "\t\tvalidation_split = 0\n",
    "\t\tmultilabel = 0\n",
    "\t\ttrain_len = 0\n",
    "\t\tepochs = 75\n",
    "\t\tbatch_size = 100\n",
    "\t\tbugfix = 0\n",
    "\telse:\n",
    "\t\t#get parameters from user input\n",
    "\t\tascad_database, training_model, network_type, epochs, batch_size, train_len, validation_split, multilabel, early_stopping = read_parameters_from_file(sys.argv[1])\n",
    "\n",
    "\t#load traces\n",
    "\t(X_profiling, Y_profiling), (X_attack, Y_attack) = load_ascad(ascad_database)\n",
    "\n",
    "\t#get network type\n",
    "\tif(network_type==\"mlp\"):\n",
    "\t\tbest_model = my_mlp(input_dim=len(X_profiling[0]))\n",
    "\telse: #display an error and abort\n",
    "\t\tprint(\"Error: no topology found for network '%s' ...\" % network_type)\n",
    "\t\tsys.exit(-1);\n",
    "\t#  print best_model.summary()\n",
    "\n",
    "\t### training\n",
    "\tif (train_len == 0):\n",
    "\t\ttrain_model(X_profiling, Y_profiling, best_model, training_model, epochs, batch_size, multilabel, validation_split, early_stopping)\n",
    "\telse:\n",
    "\t\ttrain_model(X_profiling[:train_len], Y_profiling[:train_len], best_model, training_model, epochs, batch_size, multilabel, validation_split, early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804039a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087d8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
